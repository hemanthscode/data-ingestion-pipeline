# Data Ingestion Pipeline Configuration (ETL-Ready Defaults)

paths:
  raw_data: "data/raw"
  processed_data: "data/processed"
  reports: "data/reports"
  logs: "logs"

ingestion:
  supported_formats: ["csv", "xlsx", "xls", "json", "parquet"]
  encoding: "utf-8"
  max_file_size_mb: 500
  chunk_size: 10000

cleaning:
  missing_values:
    strategy: "fill_median"    # ← FIXED: Explicit, not "auto"
    threshold: 0.5
  duplicates:
    keep: "first"
    subset: null
  outliers:
    method: "iqr"
    threshold: 1.5
    action: "cap"

transformation:
  categorical_encoding:
    method: "onehot"           # ← FIXED: Explicit method
    handle_unknown: "ignore"
    max_categories: 50
  numerical_scaling:
    method: "none"             # ← FIXED: ETL = business readable!
    skip_phone_numbers: true
    business_columns:
      - age
      - salary
      - phone
      - employee_id
  feature_engineering:
    create_datetime_features: true
    create_interaction_features: false
    polynomial_features: false

validation:
  check_data_types: true
  check_ranges: true
  check_uniqueness: true
  generate_profile: true

quality:
  min_completeness: 0.7
  max_duplicate_ratio: 0.1

export:
  formats: ["csv", "parquet"]
  include_metadata: true
  include_report: true
  compression: "gzip"

logging:
  level: "INFO"
  format: "json"
  rotation: "10 MB"
